%% LyX 2.1.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass{article}
\usepackage[latin9]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\begin{document}

\title{\textbf{Programming 2 Assignment}}


\author{Gerald Hu, Aaron Skouby \\
 \\
 CSCE 221-200}


\date{March 11, 2016}

\maketitle

\section*{Introduction}

The purpose of this assignment was to explore and gain understanding
of data structures and implementations that were discussed in class.
This project explored implementing a map ADT using a binary tree.
The performance of the map's operations was analyzed for both a binary
search tree implementation and an AVL binary tree implementation.
Functionality was written for the map that allowed it to insert, delete,
access, and edit key-value pairs. Additionally, some lower level details
on the tree representation itself were implemented, including functions
that allowed searching, inserting, and deleting from the underlying
tree as well as rebalancing the tree after these insertions and deletions.
The results of this assignment and its timing tests demonstrated the
theoretical performance analysis that was determined in class for
the binary search tree and the AVL tree. The running time of the insertions,
searches, and deletions are all the same as each other because they
are based of the height of the tree. The best case and average case
for both types of tree was $O(\log{n})$. The difference existed in
the worst case scenario. For the AVL tree this was still $O(\log{n})$,
but for binary search trees it was $O(n)$. The AVL tree did its job
of making sure that the worst case is still $O(\log{n})$.


\section*{Implementation Details}

The map was implemented with a binary search tree, using the AVL method
of self-balancing. The tree had node data members, a size\_t ``sz''
which kept track of the size of the tree, special ``leaf'' nodes
at the end of each branch with no key or value, and a special ``superroot''
node whose left subtree was the main tree and a null parent. Each
node of the tree stored pointers to its parent, left child, and right
child, as well as storing a pair called ``value''. This pair was
the main data element of the node, storing the key, or index, in its
first position, and the data value in its second position. The pair
used the standard template library pair. \\


\noindent The map had two erase functions, one which took a key, one
which took an iterator for position. These would take a key or iterator
and find the desired node, and would get a pointer to it. Then, it
would pass the node pointer to a helper function eraser(node{*} n),
which would find the node (or otherwise do nothing), remove it, place
the child in the proper position, and return the next node in an in-order
traversal. Insert functions were implemented similarly to the eraser
functions. Similarly, there were two insert functions, with one taking
a key, the other taking an iterator, and both being based on an inserter
helper function. The inserter function would take a key and value,
and would either construct a new node and add it to the map; or, in
the case where the key already existed in a map, replace that key's
value with the new value.\\


\noindent The map's size was automatically adjusted by the helper
functions eraser() and inserter() when needed. Both eraser() and inserter()
called rebalance() to fix tree imbalances after doing their respective
operation. Rebalance() would scan up the tree to find imbalances,
and call the restructure() function on them, making appropriate left
or right rotations to maintain the AVL balance conditions (that is,
that the maximum difference between the left and right subtrees of
any node was less than or equal to 1).\\


\noindent Timing.cpp was essentially unchanged from the code provided
by the instructors. The timing function was already implemented, and
for the most part our tests simply changed the parameters of the function.
This timing function relies on high\_resolution\_clock; given a map
and a number, the function would repeatedly push random elements into
the map the specified number of times.\\



\section*{Theoretical Analysis}

\noindent For insert and erase operations on a simple binary search
tree, the worst case occurs when the position to insert the node or
of the node to be erased is at the bottom of the tree. This means
that the function must traverse the entire tree's height before it
can perform its operation. The tree's height can change, varying from
$O(\log{n})$ to $O(n)$, but the performance of the insert and erase
functions will always depend on the height. Thus, the insert and erase
functions are $O(h)$, where $h$ is the height of the tree.\\


\noindent The rebalancing on an AVL tree is based off of the linked-node
implementation. A single restructure around one node is O(1) because
it is simply reassigning the pointers of three nodes. Rebalance()
travels up the entire tree's height to ensure that all nodes above
the changed point are balanced, which is $O(h)$. The cumulative restructure
is O(1){*}O(h) = O(h). For AVL trees, the height will be $O(\log{n})$,
so the rebalance is $O(\log{n})$.\\


\noindent For the insert and erase operations on an AVL tree there
is a logarithmic bound on the height of the tree. Since the insert
and delete functions are the same as for a regular binary search tree
except with rebalance added, their performance is still $O(h)$. This
is because the insert/delete is $O(h)$, as discussed earlier, and
rebalancing is $O(h)$, and $O(h+h)$ is $O(h)$. For AVL trees, the
height will be $O(\log{n})$, so the insert and delete is $O(\log{n})$.
\\


\noindent To prove that height on AVL trees is logarithmically bounded,
begin with a function $n(h)$ that returns the minimum number of internal
nodes of an AVL tree with height $h$. Note that an AVL tree wiith
the minimum number of nodes for that height contains a root node,
the minimal subtree of height $h-1$, and the minimal subtree of height
$h-2$. That means that $n(h)$ for the tree is $1+n(h-1)+n(h-2)$.
Because it a node has to be added to get from the minimal tree with
height $h-2$ to the minimal tree with height $h-1$, $n(h-1)>n(h-2)$.
Substituting that fact into the equation for $n(h)$, the expression
$1+n(h-1)+n(h-2)>2n(h-2)$ is obtained. As a result, $n(h)>2n(h-2)$.
By extending this fact back recursively, $2n(h-2)$ can be substituted
with $4n(h-4)$, and and so on until the pattern $n(h)>2^{i}n(h-2i)$
is determined. \\


\noindent When evaluating this for the base case of $n(1)=1$, an
AVL tree with height 1, substituting that in and solving for $i$
gives $i=(\frac{h}{2}-1)$. This produces $n(h)>2^{\frac{h}{2}-1}$,
which can be rearranged to $h<2(log(n(h)))+2$, which is a logarithmic
bound on the height of the AVL trees.\\



\section*{Experimental Setup}

Timing tests were conducted using the provided timing.cpp, compiled
with the provided makefile's commands. Compilation was done on the
``linux.cse.tamu.edu'' server, with G++ version 4.7.3 (SUSE Linux)
(found via g++ --version). Compilation was set to the C++11 standard,
with the -G flag enabled and O2 optimization level, warnings set to
-Wall -Werror (all warnings treated as compilation errors), and dependencies
flagged with -MMD (auto-generate dependencies).\\


\noindent Tests were run on the ``compute.cse.tamu.edu'' server,
which runs Arch Linux x86\_64 version 8.12 (found via arch --version
and lsb\_release -a). This server has 99026668 total kilobytes of
RAM (found via free). It uses Intel Core i7-3970X CPUs (2 sockets,
8 cores per socket, 2 threads per core), with a clock speed of 2000
mHz (found via lscpu). Each core has a Xeon E5-2650 processor (found
via lshw --short).\\


\noindent Timing functions output timing results for input sizes that
were powers of 2, starting from 2 itself, and ending at a maximum
size specified by the user. Each step of the timing was repeated 10
times, and the average of each result taken. Linear height n inserts
went up to a maximum input size of 32768; logarithmic height n inserts
went up to a maximum input size of 4194304, and random n inserts went
up to a maximum input size of 1048576.\\


\noindent timing.o was run twice: first on a tree with AVL rebalancing
and then on a simpler binary tree with no rebalancing method. These
results for the performance were then compared between the two trees.


\section*{Results and Discussion}

In testing the timing performance of the functions for the binary
search tree and AVL tree implementations of the map ADT, only the
insert function was tested. As was discussed in the theoretical analysis
section, all of the three main functions of the map ADT (find, insert,
snd erase) for the binary search tree and AVL tree have the same asymptotic
running time. As a result it is only necessary to test one of the
functions because the results should be asymptotically the same for
the other two as well. \\


\begin{figure}[h]
\includegraphics[width=11cm]{report/Linear_Time_Per_(Binary)} \caption{Graph of the Time Taken per Addition for Different Input Sizes for
a Linear Order Added Binary Search Tree}
\label{fig:Linear_Time_Per_Binary} 
\end{figure}


\begin{figure}[h]
\includegraphics[width=11cm]{report/Linear_Time_Per_(AVL)} \caption{Graph of the Time Taken for Different Input Sizes for a Linear Order
Added AVL Tree}
\label{fig:Linear_Time_Per_AVL} 
\end{figure}


\begin{figure}[h]
\includegraphics[width=11cm]{report/Linear_Big_O_(Binary)} \caption{Graph of the Big O Constants for Different Input Sizes for a Linear
Order Added Binary Search Tree}
\label{fig:Linear_Big_O_Binary} 
\end{figure}


\begin{figure}[h]
\includegraphics[width=11cm]{report/Linear_Big_O_(AVL)} \caption{Graph of the Big O Constants for Different Input Sizes for a Linear
Order Added AVL Tree}
\label{fig:Linear_Big_O_AVL} 
\end{figure}


\noindent The first set of timing tests that was run on the code was
for linearly inserted elements. This means that if the structure of
the tree not changed by rebalancing, the tree would have a height
that is $O(n)$, where $n$ is the number of nodes in the tree. These
tests should result in the worst case for the insertions. This test
was first run on the normal binary search tree, then on the AVL tree.
As predicted by the theoretical analysis, the time taken by the normal
binary search tree was $O(n)$ (because $h$ is $O(n)$). This is
seen in Figure~\ref{fig:Linear_Time_Per_Binary}, where the time
per one insertion goes up basically linearly with respect to the input
size. In contrast, the AVL tree runs in $O(\log{n})$ time, as is
clearly seen in the logarithmic shape of the graph in Figure~\ref{fig:Linear_Time_Per_AVL}.
\\


\noindent The Big O constants were calculated for both types of trees.
They were calculated by dividing the time per insertion by the expected
time for each insertion, which is $n$ for the regular binary search
tree and $\log{n}$ for the AVL tree. The graphs of both of these
results (Figures~\ref{fig:Linear_Big_O_Binary} and~\ref{fig:Linear_Big_O_AVL})
flatten out for their larger input sizes, suggesting that the flattened
value is the Big O constant. The Big O constant for the binary search
tree was $1*10^{-8}$ , and the constant for the AVL tree was $5*10^{-8}$.
The Big O constant is actually larger for the AVL tree than for the
binary search tree. This is inconsequential, however, because their
Big O functions are not the same. Comparing Big O constants is only
meaningful when the functions are the same. In this case, for larger
input values (i.e. asymptotically) the binary search tree will be
much slower because $O(n)$ is much larger than $O(\log{n})$.\\


\begin{figure}[h]
\includegraphics[width=11cm]{report/Logarithmic_Time_Per_(Binary)}
\caption{Graph of the Time Taken per Addition for Different Input Sizes for
a Logarithmic Order Added Binary Search Tree}
\label{fig:Logarithmic_Time_Per_Binary} 
\end{figure}


\begin{figure}[h]
\includegraphics[width=11cm]{report/Logarithmic_Time_Per_(AVL)} \caption{Graph of the Time Taken for Different Input Sizes for a Logarithmic
Order Added AVL Tree}
\label{fig:Logarithmic_Time_Per_AVL} 
\end{figure}


\begin{figure}[h]
\includegraphics[width=11cm]{report/Logarithmic_Big_O_(Binary)} \caption{Graph of the Big O Constants for Different Input Sizes for a Logarithmic
Order Added Binary Search Tree}
\label{fig:Logarithmic_Big_O_Binary} 
\end{figure}


\begin{figure}[h]
\includegraphics[width=11cm]{report/Logarithmic_Big_O_(AVL)} \caption{Graph of the Big O Constants for Different Input Sizes for a Logarithmic
Order Added AVL Tree}
\label{fig:Logarithmic_Big_O_AVL} 
\end{figure}


\noindent The next set of tests used logarithmically inserted elements,
meaning that the structure of the tree would be logarithmic if it
was not changed by rebalancing. These tests should yield the best
case for the insertions. Like the last tests, these tests were run
on the binary search tree first, then on the AVL tree. Again, the
results agreed with the theoretical predictions made earlier. The
time taken per insertion with respect to input size for the binary
search tree was $O(\log{n})$ this time, as is seen in Figure~\ref{fig:Logarithmic_Time_Per_Binary}.
This is still $O(h)$; but $h$ is now $O(\log{n})$, instead of $O(n)$
as it was in the last case. Also, as was expected, the results for
the AVL tree were $O(\log{n})$ (Figure~\ref{fig:Logarithmic_Time_Per_AVL}).
\\


\noindent The agreement between the theoretical and actual results
was further confirmed when looking at the Big O constants for the
logarithmic insertions. In this case, the expected time for insertion
for both the binary search tree and the AVL tree were $\log{n}$.
For both tree types, the results for the Big O constants flattened
out for larger input sizes (Figures~\ref{fig:Logarithmic_Big_O_Binary}
and~\ref{fig:Logarithmic_Big_O_AVL}), suggesting that the constants
are correct, as are the Big O functions. The Big O constant appears
to be about $4*10^{-8}$ for the binary search tree and $4*10^{-8}$
for the AVL tree as well. These constants can be compared this time
because the Big O functions are the same ($O(\log{n})$). In this
case they have approximately the same constant, meaning that they
should take approximately the same amount of time. This is significant
because it shows that the overhead for the checks in restructuring
are not significant. The time actually taken for restructures cannot
be determined because they were not needed for this tree shape, but
the checks still occurred and had no discernible impact on the Big
O constant. \\


\begin{figure}[h]
\includegraphics[width=11cm]{report/Random_Time_Per_(Binary)} \caption{Graph of the Time Taken per Addition for Different Input Sizes for
a Random Order Added Binary Search Tree}
\label{fig:Random_Time_Per_Binary} 
\end{figure}


\begin{figure}[h]
\includegraphics[width=11cm]{report/Random_Time_Per_(AVL)} \caption{Graph of the Time Taken for Different Input Sizes for a Random Order
Added AVL Tree}
\label{fig:Random_Time_Per_AVL} 
\end{figure}


\begin{figure}[h]
\includegraphics[width=11cm]{report/Random_Big_O_(Binary)} \caption{Graph of the Big O Constants for Different Input Sizes for a Random
Order Added Binary Search Tree}
\label{fig:Random_Big_O_Binary} 
\end{figure}


\begin{figure}[h]
\includegraphics[width=11cm]{report/Random_Big_O_(AVL)} \caption{Graph of the Big O Constants for Different Input Sizes for a Random
Order Added AVL Tree}
\label{fig:Random_Big_O_AVL} 
\end{figure}


\noindent The last tests that were run were intended to test the average
case for the insertion. This case was the randomly inserted case where
elements were put in the tree in no particular order. The shape of
this tree before restructuring could be anywhere between logarithmic
and linear. The test were run for both the binary search tree and
the AVL tree. \\


\noindent The results for both types of trees were what was predicted.
The results for the time taken per insertion for a binary search tree
were $O(\log{n})$ as can be seen in the graph in Figure~\ref{fig:Random_Time_Per_Binary}.
Since on average the height of a binary search tree will be $O(\log{n})$,
$O(h)=O(\log{n})$, so the results agree with the predictions. The
results for the AVL tree (Figure~\ref{fig:Random_Time_Per_AVL})
show that the insertion for the AVL tree with random trees is also
$O(\log{n})$. This agrees with the theoretical analysis that operations
on the AVL tree are always $O(\log{n})$. \\


\noindent The Big O constants were calculated for both the binary
search tree and the AVL tree. The function that they were both compared
to was $\log{n}$. The graphs of the Big O constants ((Figures~\ref{fig:Random_Big_O_Binary}
and~\ref{fig:Random_Big_O_AVL}) basically flattened out, showing
that the correct Big O function was chosen. The graphs do not quite
flatten out, possibly because the randomness of the inputs was not
quite normalized by the input size. The Big O constant for the binary
search tree was about $9*10^{-8}$ while the constant for the AVL
tree was about $6*10^{-8}$. Since both functions are $O(\log{n})$,
their Big O constants can be compared. The fact that the constant
for the AVL tree is smaller than that of the binary search tree shows
that the AVL tree is better on average. The cost that AVL trees take
in restructuring the elements is less than the cost that the binary
search tree takes in having taller trees. \\


\noindent When comparing the performance of the insertion for either
the binary search tree or the AVL tree, the worst and best cases can
be determined. The results show that the worst, best, and average
cases are what they were expected to be. For the binary search tree,
the linear case was obviously the worst case because it was $O(n)$
while the other two cases were $O(\log{n})$. Looking at the remaining
cases, logarithmic is the best case because it has a Big O constant
of $4*10^{-8}$ while the random case has a Big O constant of $9*10^{-8}$.
The same order holds for the AVL tree. Since its insertions were all
$O(\log{n})$, the cases can be ordered solely by Big O constants.
Since the linear case has fewer inputs, it is important to measure
the Big O constants around the highest input size that the linear
case received, 16384. The Big O constants for the linear, logarithmic,
and random cases around that point are $5.0*10^{-8}$, $2.5*10^{-8}$,
and $4*10^{-8}$, respectively. That means that the best case is the
logarithmic case and the worst case is the linear case, as was expected.


\section*{Conclusion}

This assignment achieved a few main goals. First and foremost, it
deepened our understanding of the way maps and binary search trees
work. It also introduced, in a practical way, how to use AVL trees.
And it verified the theoretical discussions held in class about the
performance of functions of the ADT implementation. The advantages
of the AVL tree were concretely seen in the performance difference
between the regular binary search tree and the AVL tree. From the
timing results obtained in this assignment, it can be seen that AVL
trees are better than or on par with binary search trees in every
situation. Overall, this assignment as a whole gave needed practice
in coding as well as reinforced concepts that were learned in class. 
\end{document}
